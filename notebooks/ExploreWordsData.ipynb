{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add erpsc to path\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_path = '/Users/vassiki/Desktop/nhw17/ERPSC_NLP/'\n",
    "#sys.path.append(os.getcwd)\n",
    "sys.path.append(my_path)\n",
    "# ^ Update the above with a link to the folder that has 'erpsc' in it, if not currently in path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import erpsc\n",
    "from erpsc.base import Base\n",
    "from erpsc.core.db import ERPDB\n",
    "from erpsc.erp_data import ERPData\n",
    "from erpsc.erp_data_all import ERPDataAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add data to path\n",
    "db = ERPDB(False)\n",
    "db.project_path = os.path.join(os.getcwd(), 'dat')\n",
    "db.gen_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/Users/vassiki/Desktop/nhw17/ERPSC_NLP/notebooks/dat/2-Data/words/raw/P300.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-874bd2a79901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load raw data from a particular ERP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0merp_dat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mERPData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'P300'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0merp_dat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/vassiki/Desktop/nhw17/ERPSC_NLP/erpsc/erp_data.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, db)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_json_dat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/raw/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vassiki/Desktop/nhw17/ERPSC_NLP/erpsc/erp_data.pyc\u001b[0m in \u001b[0;36m_parse_json_dat\u001b[0;34m(f_name)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_parse_json_dat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/Users/vassiki/Desktop/nhw17/ERPSC_NLP/notebooks/dat/2-Data/words/raw/P300.json'"
     ]
    }
   ],
   "source": [
    "# Load raw data from a particular ERP\n",
    "erp_dat = ERPData('P300')\n",
    "erp_dat.load(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'An event-related potential study on the time course of mental rotation in upper-limb amputees.',\n",
       " u'An Efficient Framework for EEG Analysis with Application to Hybrid Brain Computer Interfaces Based on Motor Imagery and P300.',\n",
       " u'Social Distance Influences the Outcome Evaluation of Cooperation and Conflict: Evidence from Event-Related Potentials.',\n",
       " u'The processing of body expressions during emotional scenes: the modulation role of attachment styles.',\n",
       " u'Cortical Sensitivity to Guitar Note Patterns: EEG Entrainment to Repetition and Key.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of articles\n",
    "erp_dat.n_articles\n",
    "erp_dat.titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keyword Data\n",
    "erp_dat.kws[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Words are stored as a 'bag of words', with punctuation, and 'stopwords' already removed\n",
    "numArticles = 5\n",
    "\n",
    "for i in xrange(numArticles):\n",
    "    print('Number of words in article number %d was %d') %(i,len(erp_dat.words[i])) \n",
    "    \n",
    "len(erp_dat.words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "erp_dat.authors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import itertools \n",
    "import nltk.text\n",
    "from nltk import ContextIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_corpus(ds):\n",
    "    \"\"\"\n",
    "    To flatten all article words into a long list, while retaining details about the\n",
    "    article number the words came from, to later invert the data structure \n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    ds : Data structure returned by ERFSC when a query is submitted\n",
    "    \"\"\"\n",
    "    aPreCorpus = []\n",
    "    \n",
    "    numArticles = ds.n_articles\n",
    "    print('Iterating over %d articles for extracting words') %(ds.n_articles)\n",
    "    for AIdx in xrange(numArticles):\n",
    "        if ds.words[AIdx] != None:\n",
    "            aPreCorpus.append(ds.words[AIdx])\n",
    "        \n",
    "    \n",
    "    PreText = list(itertools.chain.from_iterable(aPreCorpus))\n",
    "    \n",
    "    Corpus = nltk.Text(PreText)\n",
    "    \n",
    "    return Corpus\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_common_words(Corpus,NumWords):\n",
    "    \"\"\"\n",
    "    Return the most common words in the concatenated article text corpus\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    Corpus: generated from keyword arguments from cognitive atlas\n",
    "    NumWords: Top N words to return\n",
    "    \"\"\"\n",
    "    \n",
    "    assert(NumWords <= len(Corpus))\n",
    "    \n",
    "    fdist = nltk.FreqDist(Corpus)\n",
    "    common_words = fdist.most_common(NumWords)\n",
    "    header = [('Term', 'Frequency'),('-'*len('Term'),'-'*len('Frequency'))]\n",
    "    wordList = header + common_words\n",
    "    \n",
    "    width = max(len(e) for t in wordList for e in t[:-1]) + 1 \n",
    "    format=('%%-%ds' % width) * len(wordList[0])\n",
    "    print '\\n'.join(format % tuple(t) for t in wordList)\n",
    "    print('\\n Total Word Count : %d') %(len(Corpus))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_similarity(Corpus,ds,keyword='cognition'):\n",
    "    \"\"\"\n",
    "    Returns the most similar words, determined by neighborhood in corpus\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    \n",
    "    Corpus : concatenated list of abstracts\n",
    "    ds : ouptut of lisc\n",
    "    keyword : query\n",
    "    \"\"\"\n",
    "    #similar_words = Corpus.similar(keyword)\n",
    "    #return similar_words\n",
    "    #similar_words = Corpus._word_contex_index.similar_words(keyword)\n",
    "    #if similar_words != None:\n",
    "     #   print '\\n'.join(word for word in similar_words)\n",
    "    #else: \n",
    "     #   print 'No matches.'\n",
    "        \n",
    "    idx = nltk.text.ContextIndex([word.lower() for word in Corpus])\n",
    "    save = []\n",
    "    for word in nltk.word_tokenize(keyword):\n",
    "        save.append(idx.similar_words(word))\n",
    "        if word != None:\n",
    "            print '\\n'.join(idx.similar_words(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating over 4992 articles for extracting words\n"
     ]
    }
   ],
   "source": [
    "Corpus = get_corpus(erp_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term       Frequency  \n",
      "----       ---------  \n",
      "p300       9910       \n",
      "patients   3650       \n",
      "amplitude  3050       \n",
      "stimuli    2503       \n",
      "subjects   2444       \n",
      "latency    2436       \n",
      "study      2431       \n",
      "potentials 2408       \n",
      "auditory   2286       \n",
      "task       2268       \n",
      "\n",
      " Total Word Count : 442877\n"
     ]
    }
   ],
   "source": [
    "get_common_words(Corpus,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cognitive\n",
      "working\n",
      "plus\n",
      "integration\n",
      "structure\n",
      "effects\n",
      "potentials\n",
      "age\n",
      "stimuli\n",
      "abilities\n",
      "followed\n",
      "findings\n",
      "p3b\n",
      "executive\n",
      "brain\n",
      "signs\n",
      "morphology\n",
      "curcumin\n",
      "children\n",
      "prodromal\n"
     ]
    }
   ],
   "source": [
    "sw = get_similarity(Corpus,erp_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.text\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = nltk.text.ContextIndex([word.lower( ) for word in Corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save = [ ]\n",
    "for word in nltk.word_tokenize('cognition'):\n",
    "    save.append(idx.similar_words(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'cognitive',\n",
       "  u'working',\n",
       "  u'plus',\n",
       "  u'integration',\n",
       "  u'structure',\n",
       "  u'effects',\n",
       "  u'potentials',\n",
       "  u'age',\n",
       "  u'stimuli',\n",
       "  u'abilities',\n",
       "  u'followed',\n",
       "  u'findings',\n",
       "  u'p3b',\n",
       "  u'executive',\n",
       "  u'brain',\n",
       "  u'signs',\n",
       "  u'morphology',\n",
       "  u'curcumin',\n",
       "  u'children',\n",
       "  u'prodromal']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "\n",
    "1. Test functions with lisc instead of erpsc\n",
    "2. Find out the CA terms can be checked within the corpus\n",
    "3. Submit a pull request to add a version of this notebook to NHW repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potentials cognitive integration effects age stimuli abilities\n",
      "followed findings generation executive observed brain signs morphology\n",
      "curcumin children based rt evaluation\n"
     ]
    }
   ],
   "source": [
    "Corpus.similar('cognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim = Corpus._word_context_index.similar_words('cognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'cognitive',\n",
       " u'working',\n",
       " u'plus',\n",
       " u'potentials',\n",
       " u'generation',\n",
       " u'integration',\n",
       " u'structure',\n",
       " u'effects',\n",
       " u'age',\n",
       " u'stimuli',\n",
       " u'abilities',\n",
       " u'followed',\n",
       " u'findings',\n",
       " u'cerebral',\n",
       " u'observed',\n",
       " u'brain',\n",
       " u'perception',\n",
       " u'signs',\n",
       " u'morphology',\n",
       " u'curcumin']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gnitiveOntology development by creating an account on GitHub.\" property=\"og:description\" />\\n\\n  <link rel=\"assets\" href=\"https://assets-cdn.github.com/\">\\n  \\n  <meta name=\"pjax-timeout\" content=\"1000\">\\n  \\n  <meta name=\"request-id\" content=\"C914:884F:5AF197:8BFD33:59B1BC60\" data-pjax-transient>\\n  \\n\\n  <meta name=\"selected-link\" value=\"repo_source\" data-pjax-transient>\\n\\n  <meta name=\"google-site-verification\" content=\"KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU\">\\n<meta name=\"google-site-verification\" content=\"ZzhVyEFwb7w3e0-uOTltm8Jsck2F5StVihD0exw2fsA\">\\n    <meta name=\"google-analytics\" content=\"UA-3769691-2\">\\n\\n<meta content=\"collector.githubapp.com\" name=\"octolytics-host\" /><meta content=\"github\" name=\"octolytics-app-id\" /><meta content=\"https://collector.githubapp.com/github-external/browser_event\" name=\"octolytics-event-url\" /><meta content=\"C914:884F:5AF197:8BFD33:59B1BC60\" name=\"octolytics-dimension-request_id\" /><meta content=\"sea\" name=\"octolytics-dimension-region_edge\" /><meta cont'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurence 31 of p300 preceded by activity and followed by rotation.\n",
      "Occurence 60 of p300 preceded by mental and followed by body.\n",
      "Occurence 77 of p300 preceded by rotation and followed by parts.\n",
      "Occurence 91 of p300 preceded by body and followed by involves.\n",
      "Occurence 174 of p300 preceded by parts and followed by sequential.\n",
      "Occurence 181 of p300 preceded by involves and followed by cognitive.\n",
      "Occurence 194 of p300 preceded by sequential and followed by processes.\n",
      "Occurence 199 of p300 preceded by cognitive and followed by including.\n",
      "Occurence 303 of p300 preceded by processes and followed by visual.\n",
      "Occurence 320 of p300 preceded by including and followed by processing.\n"
     ]
    }
   ],
   "source": [
    "max_instances = 10\n",
    "\n",
    "indices = [i for i, x in enumerate(plain_list) if x == \"p300\"]\n",
    "\n",
    "check_first = indices[:max_instances]\n",
    "\n",
    "for i in range(max_instances):\n",
    "    print('Occurence %d of p300 preceded by %s and followed by %s.') %(check_first[i],plain_list[i-1],plain_list[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SAVING WHAT THE WORD IS SIMILAR TO\n",
    "similar_words = Corpus._word_context_index.similar_words('p300')\n",
    "print ' '.join(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'preferred'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import ContextIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "similar_words = Corpus._word_context_index.similar_words('p300')\n",
    "print ' '.join(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CA_words = ['p300','abductive reasoning','abstract analogy','p300','abstract knowledge','acoustic coding','acoustic encoding','acoustic phonetic processing','acoustic processing','action','action initiation','action perception']\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p300', 'p300', 'action']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_word_presence(Corpus,CA_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
